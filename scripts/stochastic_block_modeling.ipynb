{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08ccb829-8791-4e0d-81f4-bd78a010b984",
   "metadata": {},
   "source": [
    "# Stochastic Block Modeling\n",
    "\n",
    "Calculate the cosine similarity matrix for afferent and efferent shared regions. Run SBM on this to infer the graph structure and determine clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2080e366-bb79-4d5e-8206-702e2a868ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bct\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns # Using seaborn for prettier plotting\n",
    "import plotly.graph_objects as go\n",
    "from plotly.colors import qualitative\n",
    "import graph_tool.all as gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802f7352-a94a-4926-b0a8-35571f71ce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_average = pd.read_csv('../data/average_connectome_data.csv', header=0, index_col=0)\n",
    "\n",
    "# filter the afferent / efferent based on hippocampal connections, create similarity matrix\n",
    "hippocampal_regions = np.array(['DG','CA3','CA2','CA1v','CA1d','SUBv','SUBd'])\n",
    "\n",
    "# FROM hippocampus (efferent)\n",
    "df_avg_from = df_average[df_average.index.isin(hippocampal_regions)]\n",
    "\n",
    "# TO hippocampus (afferent)\n",
    "df_average_t = df_average.T\n",
    "df_avg_to = df_average_t[df_average_t.index.isin(hippocampal_regions)]\n",
    "\n",
    "# drop HPC columns\n",
    "df_avg_from = df_avg_from.drop(hippocampal_regions, axis=1)\n",
    "df_avg_to = df_avg_to.drop(hippocampal_regions, axis=1)\n",
    "\n",
    "# filter to only include columns and rows with at least one connection\n",
    "df_avg_from = df_avg_from.loc[:,df_avg_from.apply(np.count_nonzero, axis=0) >= 1]\n",
    "df_avg_to = df_avg_to.loc[:,df_avg_to.apply(np.count_nonzero, axis=0) >= 1]\n",
    "\n",
    "# find the shared regions\n",
    "common_cols = df_avg_to.columns.intersection(df_avg_from.columns)\n",
    "df_avg_to_shared = df_avg_to[common_cols]\n",
    "df_avg_from_shared = df_avg_from[common_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "623ee6cd-78b7-4406-87f2-dbd655a05a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run cosine similarity\n",
    "cosine_from_shared_values = cosine_similarity(df_avg_from_shared.T)\n",
    "cosine_from_shared_labels = df_avg_from_shared.columns\n",
    "\n",
    "cosine_df_from_shared = pd.DataFrame(cosine_from_shared_values, \n",
    "                             index=df_avg_from_shared.columns, \n",
    "                             columns=df_avg_from_shared.columns)\n",
    "\n",
    "cosine_to_shared_values = cosine_similarity(df_avg_to_shared.T)\n",
    "cosine_to_shared_labels = df_avg_to_shared.columns\n",
    "\n",
    "cosine_df_to_shared = pd.DataFrame(cosine_to_shared_values, \n",
    "                             index=df_avg_to_shared.columns, \n",
    "                             columns=df_avg_to_shared.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99dd9f52-bce3-4d11-b231-81c66845f899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph created with 72 vertices and 2556 edges.\n"
     ]
    }
   ],
   "source": [
    "# start with efferent similarity matrix\n",
    "\n",
    "N = 100\n",
    "\n",
    "# np.fill_diagonal(cosine_dist_matrix, 0)\n",
    "\n",
    "N = cosine_from_shared_values.shape[0]\n",
    "\n",
    "# 1. Create a new undirected graph\n",
    "g = gt.Graph(directed=False)\n",
    "\n",
    "# 2. Add all N nodes to the graph\n",
    "g.add_vertex(n=N)\n",
    "\n",
    "# 3. Create an edge property map to store our weights (the distances)\n",
    "# We use \"double\" for floating-point numbers\n",
    "weights = g.new_edge_property(\"double\")\n",
    "\n",
    "# 4. Add edges and their weights from the matrix\n",
    "# We iterate over the upper triangle of the matrix (k=1 to skip the diagonal)\n",
    "rows, cols = np.triu_indices(N, k=1)\n",
    "\n",
    "# Create a list of edges with their weights\n",
    "# (This is much faster than adding them one by one)\n",
    "edge_list = [(r, c, cosine_from_shared_values[r, c]) for r, c in zip(rows, cols)]\n",
    "\n",
    "# Add all edges to the graph at once\n",
    "g.add_edge_list(edge_list, eprops=[weights])\n",
    "\n",
    "# 5. Store the weights as an internal property of the graph\n",
    "# This makes it easier to access later\n",
    "g.edge_properties[\"weight\"] = weights\n",
    "\n",
    "print(f\"Graph created with {g.num_vertices()} vertices and {g.num_edges()} edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f3c477a-18dd-440e-aaf7-c7bf6ba7dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "state=gt.minimize_blockmodel_dl(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bff21fa6-7dbd-41ef-8df5-1294f51fdfac",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute 'pos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/br2f/lib/python3.12/site-packages/graph_tool/__init__.py:1700\u001b[0m, in \u001b[0;36mPropertyDict.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1700\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(attr)\n\u001b[1;32m   1701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/br2f/lib/python3.12/site-packages/graph_tool/__init__.py:1608\u001b[0m, in \u001b[0;36mPropertyDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p[p\u001b[38;5;241m.\u001b[39mget_graph()]\n\u001b[0;32m-> 1608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__properties[(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__t, key)]\n",
      "\u001b[0;31mKeyError\u001b[0m: ('v', 'pos')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m state\u001b[38;5;241m.\u001b[39mdraw(pos\u001b[38;5;241m=\u001b[39mg\u001b[38;5;241m.\u001b[39mvp\u001b[38;5;241m.\u001b[39mpos, output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mefferent_cosine_shared_regions.svg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/br2f/lib/python3.12/site-packages/graph_tool/__init__.py:1702\u001b[0m, in \u001b[0;36mPropertyDict.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m   1700\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(attr)\n\u001b[1;32m   1701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m-> 1702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28msuper\u001b[39m(PropertyDict, \u001b[38;5;28mself\u001b[39m), attr)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute 'pos'"
     ]
    }
   ],
   "source": [
    "state.draw(pos=g.vp.pos, output=\"efferent_cosine_shared_regions.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79e1d4c7-c2b8-417a-9b4c-bbc754f812e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting nested Stochastic Block Model...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "minimize_nested_blockmodel_dl() got an unexpected keyword argument 'recs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting nested Stochastic Block Model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Fit a hierarchical SBM\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# This is the Bayesian part. It minimizes the description length (DL),\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# which is equivalent to maximizing the posterior probability.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# \"real-normal\" assumes weights are drawn from a Gaussian distribution,\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# and the model will find the mu and sigma for each block-pair.\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m state \u001b[38;5;241m=\u001b[39m gt\u001b[38;5;241m.\u001b[39mminimize_nested_blockmodel_dl(g, \n\u001b[1;32m     12\u001b[0m                                           recs\u001b[38;5;241m=\u001b[39m[g\u001b[38;5;241m.\u001b[39mep\u001b[38;5;241m.\u001b[39mweight], \n\u001b[1;32m     13\u001b[0m                                           rec_types\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal-normal\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel fitting complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: minimize_nested_blockmodel_dl() got an unexpected keyword argument 'recs'"
     ]
    }
   ],
   "source": [
    "print(\"Fitting nested Stochastic Block Model...\")\n",
    "\n",
    "# Fit a hierarchical SBM\n",
    "# This is the Bayesian part. It minimizes the description length (DL),\n",
    "# which is equivalent to maximizing the posterior probability.\n",
    "#\n",
    "# We pass our edge weights via `recs` (real-valued edge covariates)\n",
    "# and specify their type via `rec_types`.\n",
    "# \"real-normal\" assumes weights are drawn from a Gaussian distribution,\n",
    "# and the model will find the mu and sigma for each block-pair.\n",
    "state = gt.minimize_nested_blockmodel_dl(g, \n",
    "                                          recs=[g.ep.weight], \n",
    "                                          rec_types=[\"real-normal\"])\n",
    "\n",
    "print(\"Model fitting complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64491804-dbf0-4423-ace8-63d831ca66b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
